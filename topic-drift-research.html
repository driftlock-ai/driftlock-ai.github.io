<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow">
    <meta name="description" content="Research on conversational topic drift in AI systems - DriftLock AI">
    <title>Topic Drift Research - DriftLock AI</title>
    <link rel="icon" type="image/svg+xml" href="logo/navy-icon-only.svg">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #2c3e50;
            background: #f8f9fa;
        }

        .header {
            background: linear-gradient(180deg, #1c1678  0%, #984ae8 100%);
            color: white;
            padding: 60px 20px;
            text-align: center;
        }

        .header-logo {
            max-width: 250px;
            height: auto;
            margin: 0 auto 30px;
            display: block;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 15px;
            font-weight: 800;
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.95;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        .back-link {
            display: inline-block;
            color: #984ae8;
            text-decoration: none;
            font-weight: 600;
            margin-bottom: 30px;
            transition: color 0.3s;
        }

        .back-link:hover {
            color: #1c1678;
        }

        .intro-box {
            background: white;
            border-radius: 12px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-left: 5px solid #984ae8;
        }

        .intro-box h2 {
            color: #984ae8;
            margin-bottom: 15px;
        }

        .paper-section {
            background: white;
            border-radius: 12px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .paper-header {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 3px solid #984ae8;
        }

        .paper-number {
            background: linear-gradient(135deg, #984ae8 0%, #1c1678 100%);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: 700;
            margin-right: 15px;
            flex-shrink: 0;
        }

        .paper-title {
            font-size: 1.4em;
            font-weight: 600;
            color: #2c3e50;
        }

        .paper-meta {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
            font-size: 0.95em;
        }

        .paper-link {
            display: inline-block;
            background: #984ae8;
            color: white;
            padding: 10px 20px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 600;
            margin: 10px 10px 10px 0;
            transition: background 0.3s;
        }

        .paper-link:hover {
            background: #1c1678;
        }

        .key-finding {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }

        .key-finding strong {
            color: #856404;
        }

        .why-relevant {
            background: #d4edda;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }

        .why-relevant strong {
            color: #155724;
        }

        .summary-section {
            background: white;
            border-radius: 12px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .summary-section h2 {
            color: #984ae8;
            margin-bottom: 20px;
        }

        .stat-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }

        .stat-card {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border-left: 4px solid #dc3545;
        }

        .stat-number {
            font-size: 2.5em;
            font-weight: 700;
            color: #dc3545;
            margin: 10px 0;
        }

        .stat-label {
            font-size: 0.9em;
            color: #5c6e7e;
            line-height: 1.3;
        }

        .acn-solution {
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border: 2px solid #28a745;
            padding: 30px;
            border-radius: 12px;
            margin: 30px 0;
        }

        .acn-solution h3 {
            color: #155724;
            margin-bottom: 15px;
        }

        ul {
            margin: 15px 0;
            padding-left: 25px;
        }

        li {
            margin: 8px 0;
        }

        footer {
            text-align: center;
            padding: 40px 20px;
            color: #718096;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2em;
            }

            .paper-header {
                flex-direction: column;
                align-items: flex-start;
            }

            .paper-number {
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <img src="logo/light-formal-verification-semantic-stability.svg" alt="DriftLock AI" class="header-logo">
        <h1>Conversational Topic Drift</h1>
        <p>How LLMs Lose Their Initial Commitments Over Multi-Turn Conversations</p>
    </div>

    <div class="container">
        <a href="index.html" class="back-link">← Back to Home</a>

        <div class="intro-box">
            <h2>The Problem</h2>
            <p>LLMs establish semantic commitments upfront (like "discuss banking security") but gradually drift off-topic during multi-turn conversations (ending up discussing "riverbank wildlife"). This isn't just a performance issue—it's a fundamental reliability problem that affects all major models and creates serious liability for enterprise deployments.</p>
        </div>

        <!-- PAPER 1 -->
        <div class="paper-section">
            <div class="paper-header">
                <div class="paper-number">1</div>
                <div class="paper-title">LLMs Get Lost In Multi-Turn Conversation</div>
            </div>

            <div class="paper-meta">
                <strong>Authors:</strong> Microsoft Research (Philippe Laban et al.)<br>
                <strong>Published:</strong> May 2025<br>
                <strong>Tested:</strong> 15 LLMs across 200,000+ conversations
            </div>

            <a href="https://arxiv.org/abs/2505.06120" class="paper-link" target="_blank">Read Paper</a>

            <div class="why-relevant">
                <strong>Key Findings:</strong>
                <ul>
                    <li>All top LLMs show <strong>39% average performance drop</strong> in multi-turn vs single-turn conversations</li>
                    <li>Analysis of 200,000+ conversations found that when LLMs take a wrong turn, <strong>they get lost and do not recover</strong></li>
                    <li>Models make early assumptions and <strong>overly rely on them</strong>, creating paths they cannot escape</li>
                    <li>Pattern holds across GPT-4o, Claude, Gemini, LLaMA, and all other tested models</li>
                </ul>
            </div>

            <div class="key-finding">
                <strong>Critical Insight:</strong> Once drift starts, models cannot self-correct. The performance degradation includes a minor loss in aptitude and a significant increase in unreliability.
            </div>
        </div>

        <!-- PAPER 2 -->
        <div class="paper-section">
            <div class="paper-header">
                <div class="paper-number">2</div>
                <div class="paper-title">Drift No More? Context Equilibria in Multi-Turn LLM Interactions</div>
            </div>

            <div class="paper-meta">
                <strong>Published:</strong> October 2024<br>
                <strong>Focus:</strong> Mathematical modeling of contextual drift dynamics
            </div>

            <a href="https://arxiv.org/html/2510.07777" class="paper-link" target="_blank">Read Paper</a>

            <div class="why-relevant">
                <strong>Key Findings:</strong>
                <ul>
                    <li>Defines <strong>contextual drift</strong> as turn-by-turn divergence during multi-turn interaction</li>
                    <li>For aligned models, divergence <strong>grows monotonically with conversation length</strong> due to memory limits and compounding errors</li>
                    <li>Drift stabilizes at finite levels but requires continuous intervention to control</li>
                </ul>
            </div>

            <div class="key-finding">
                <strong>Critical Insight:</strong> Without interventions, contextual divergence increases predictably across conversation turns, particularly in goal-driven tasks where maintaining semantic commitment is critical.
            </div>
        </div>

        <!-- PAPER 3 -->
        <div class="paper-section">
            <div class="paper-header">
                <div class="paper-number">3</div>
                <div class="paper-title">Examining Identity Drift in Conversations of LLM Agents</div>
            </div>

            <div class="paper-meta">
                <strong>Published:</strong> February 2025<br>
                <strong>Tested:</strong> 9 different LLMs across multiple model families
            </div>

            <a href="https://arxiv.org/html/2412.00804v2" class="paper-link" target="_blank">Read Paper</a>

            <div class="why-relevant">
                <strong>Key Findings:</strong>
                <ul>
                    <li>LLMs show <strong>identity drift</strong>, where interaction patterns change over time</li>
                    <li><strong>Larger models experience greater identity drift</strong></li>
                    <li>Critical finding: <strong>Assigning a persona may not help maintain identity</strong></li>
                </ul>
            </div>

            <div class="key-finding">
                <strong>Critical Insight:</strong> The model's inherent characteristics play a greater role than explicit persona assignment. This highlights that upfront commitments alone are insufficient—models will drift regardless of initial instructions.
            </div>
        </div>

        <!-- SUMMARY -->
        <div class="summary-section">
            <h2>The Problem Magnitude</h2>

            <div class="stat-grid">
                <div class="stat-card">
                    <div class="stat-number">39%</div>
                    <div class="stat-label">Average performance drop in multi-turn conversations</div>
                </div>

                <div class="stat-card">
                    <div class="stat-number">200K+</div>
                    <div class="stat-label">Conversations analyzed showing drift</div>
                </div>

                <div class="stat-card">
                    <div class="stat-number">15+</div>
                    <div class="stat-label">State-of-the-art LLMs tested - all exhibit drift</div>
                </div>

                <div class="stat-card">
                    <div class="stat-number">0%</div>
                    <div class="stat-label">Self-correction rate once drift begins</div>
                </div>
            </div>

            <h3 style="color: #dc3545; margin-top: 30px;">Why Upfront Commitments Fail</h3>
            <ul>
                <li><strong>Explicit instructions don't prevent drift:</strong> Even with persona assignment or goal statements, models drift from initial commitments</li>
                <li><strong>Memory limits cause divergence:</strong> As conversation grows, compounding errors cause increasing drift</li>
                <li><strong>Models cannot self-correct:</strong> Once a wrong turn is taken, LLMs get lost and do not recover</li>
                <li><strong>Early assumptions dominate:</strong> Models make assumptions in early turns and overly rely on them</li>
            </ul>
        </div>

        <!-- ACN SOLUTION -->
        <div class="acn-solution">
            <h3>How DriftLock's ACN Solves Topic Drift</h3>
            <p>Our Adaptive Concept Navigation (ACN) approach directly addresses the problems documented in this research:</p>

            <ul>
                <li><strong>Formal Concept Lattices:</strong> Maintain semantic position mathematically throughout conversations, preventing drift through structural constraints rather than relying on the model to "remember"</li>

                <li><strong>Mathematical Guarantees:</strong> Unlike statistical approaches that fail ~39% of the time in multi-turn settings, ACN provides 0% drift with mathematical proofs</li>

                <li><strong>No Memory Degradation:</strong> The concept lattice structure doesn't suffer from memory limits or compounding errors—semantic position is formally tracked at each turn</li>

                <li><strong>Self-Correction Built-In:</strong> If drift is attempted, the lattice structure prevents it immediately rather than requiring recovery after the fact</li>

                <li><strong>Adversarial Resistance:</strong> Formal structures cannot be gradually manipulated like statistical models can</li>
            </ul>

            <p style="margin-top: 20px; font-weight: 600; color: #155724;">
                The research shows that current approaches fundamentally cannot maintain semantic commitments in multi-turn conversations. ACN's formal verification approach is exactly what these papers demonstrate is needed but currently missing from all major LLMs.
            </p>
        </div>

        <div style="text-align: center; margin-top: 40px;">
            <a href="index.html" class="paper-link">← Back to Home</a>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 DriftLock AI, Inc. All rights reserved.</p>
        <p style="margin-top: 10px; font-size: 0.9em;">Research on conversational topic drift in AI systems</p>
    </footer>
</body>
</html>
